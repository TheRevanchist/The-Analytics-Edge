teamRank = c(1,2,3,3,4,4,4,4,5,5)
wins2012 = c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
wins2013 = c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, wins2012)
cor(teamRank, wins2013)
data(state)
statedata = cbind(data.frame(state.x77), state.abb, state.area, state.center,  state.division, state.name, state.region)
plot(statedata$x, statedata$y)
summary(statedata)
tapply(statedata$HS.Grad, statedata$state.region, mean)
boxplot(statedata$Murder~statedata$state.region)
NorthEast = subset(statedata, state.region == "Northeast")
Northeast
NorthEast$Murder
NorthEast
Model1 = lm(Income~., data = statedata)
Model1 = lm(LifeExp~., data = statedata)
Model1 = lm(Life.Exp~., data = statedata)
Model1
summary(Model1)
LinReg = lm(Life.Exp ~ Population + Income + Illiteracy + Murder + HS.Grad + Frost + Area, data=statedata)
LinReg
plot(statedata$Income, statedata$Life.Exp)
model2 = step(LinReg)
summary(model2)
summary(statedata)
summary(LinReg)
sort(predict(LinReg))
which.min(statedata$Life.Exp)
sort(abs(model2$residuals))
library(caret)
limitedTrain = train
limitedTrain$Party = NULL
preproc = preProcess(limitedTrain)
limitedTrain = predict(preproc, limitedTrain)
k = 2
distances = dist(limitedTrain, method = "euclidean")
clusterTrain = hclust(distances, method = "ward.D")
clusterTrain = cutree(clusterTrain, k = 2)
train$clustering = clusterTrain
limitedTest = test
preproc = preProcess(limitedTest)
distances = dist(limitedTest, method = "euclidean")
clusterTest = hclust(distances, method = "ward.D")
clusterTest = cutree(clusterTest, k = 2)
test$clustering = clusterTest
library(randomForest)
Forest = randomForest(Party ~., data = train, ntree = 10000)
PredictForest = predict(Forest, newdata = test)
MySubmission = data.frame(USER_ID = test$USER_ID, PREDICTION = PredictForest)
write.csv(MySubmission, "SubmissionSimpleLogRFCluster4.csv", row.names=FALSE)
library(caret)
limitedTrain = train
limitedTrain$Party = NULL
preproc = preProcess(limitedTrain)
setwd("C:/Workbench/Online Courses/The Analytics Edge/Kaggle")
library(caret)
limitedTrain = train
limitedTrain$Party = NULL
preproc = preProcess(limitedTrain)
limitedTrain = predict(preproc, limitedTrain)
k = 2
distances = dist(limitedTrain, method = "euclidean")
clusterTrain = hclust(distances, method = "ward.D")
clusterTrain = cutree(clusterTrain, k = 2)
train$clustering = clusterTrain
limitedTest = test
preproc = preProcess(limitedTest)
distances = dist(limitedTest, method = "euclidean")
clusterTest = hclust(distances, method = "ward.D")
clusterTest = cutree(clusterTest, k = 2)
test$clustering = clusterTest
library(mice)
train = read.csv("train2016.csv")
train = complete(mice(train))
test = read.csv("test2016.csv")
test = complete(mice(test))
library(caret)
limitedTrain = train
limitedTrain$Party = NULL
preproc = preProcess(limitedTrain)
limitedTrain = predict(preproc, limitedTrain)
k = 2
distances = dist(limitedTrain, method = "euclidean")
clusterTrain = hclust(distances, method = "ward.D")
clusterTrain = cutree(clusterTrain, k = 2)
train$clustering = clusterTrain
limitedTest = test
preproc = preProcess(limitedTest)
distances = dist(limitedTest, method = "euclidean")
clusterTest = hclust(distances, method = "ward.D")
clusterTest = cutree(clusterTest, k = 2)
test$clustering = clusterTest
summary(train)
library(randomForest)
Forest = randomForest(Party ~ YOB + Gender + Income + HouseholdStatus + EducationLevel + Q98059 + Q98197 + Q99480 + Q106272 + Q107869 + Q108343 + Q108617 + Q108754 + Q109244 + Q109367 + Q112270 + Q113181 + Q114386 + Q115195 + Q115602 + Q115611 + Q116441 + Q116881 + Q116953 + Q120650 + Q122771 + Q123621 + Q124122, data = train, ntree = 2000)
PredictForest = predict(Forest, newdata = test)
MySubmission = data.frame(USER_ID = test$USER_ID, PREDICTION = PredictForest)
write.csv(MySubmission, "SubmissionSimpleLogRFClusterFS.csv", row.names=FALSE)
Forest = glm(Party ~ YOB + Gender + Income + HouseholdStatus + EducationLevel + Q98059 + Q98197 + Q99480 + Q106272 + Q107869 + Q108343 + Q108617 + Q108754 + Q109244 + Q109367 + Q112270 + Q113181 + Q114386 + Q115195 + Q115602 + Q115611 + Q116441 + Q116881 + Q116953 + Q120650 + Q122771 + Q123621 + Q124122, data = train, family = binomial)
PredTest = predict(Forest, newdata=test, type="response")
threshold = 0.5
PredTestLabels = as.factor(ifelse(PredTest<threshold, "Democrat", "Republican"))
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
MySubmission = data.frame(USER_ID = test$USER_ID, PREDICTION = PredTestLabels)
write.csv(MySubmission, "SubmissionSimpleLogFS.csv", row.names=FALSE)
Forest = glm(Party ~ YOB + Gender + Income + HouseholdStatus + EducationLevel + Q98059 + Q98197 + Q99480 + Q106272 + Q107869 + Q108343 + Q108617 + Q108754 + Q109244 + Q109367 + Q112270 + Q113181 + Q114386 + Q115195 + Q115602 + Q115611 + Q116441 + Q116881 + Q116953 + Q120650 + Q122771 + Q123621 + Q124122 + YOB^2 + Gender^2 + Income^2 + HouseholdStatus^2 + EducationLevel^2, data = train, family = binomial)
PredTest = predict(Forest, newdata=test, type="response")
threshold = 0.5
PredTestLabels = as.factor(ifelse(PredTest<threshold, "Democrat", "Republican"))
# However, you can submit the file on Kaggle to see how well the model performs. You can make up to 5 submissions per day, so don't hesitate to just upload a solution to see how you did.
# Let's prepare a submission file for Kaggle (for more about this, see the "Evaluation" page on the competition site):
MySubmission = data.frame(USER_ID = test$USER_ID, PREDICTION = PredTestLabels)
write.csv(MySubmission, "SubmissionSimpleLogFS2.csv", row.names=FALSE)
